{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599047195295",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Retrieving: http://py4e-data.dr-chuck.net/known_by_Makensie.html\nRetrieving http://py4e-data.dr-chuck.net/known_by_Afonso.html\nRetrieving http://py4e-data.dr-chuck.net/known_by_Scarlet.html\nRetrieving http://py4e-data.dr-chuck.net/known_by_Kelisse.html\nRetrieving http://py4e-data.dr-chuck.net/known_by_Matt.html\nRetrieving http://py4e-data.dr-chuck.net/known_by_Ciaran.html\nRetrieving http://py4e-data.dr-chuck.net/known_by_Sukveer.html\nRetrieving http://py4e-data.dr-chuck.net/known_by_Mishkat.html\n"
    }
   ],
   "source": [
    "import urllib.request, urllib.parse,urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "link = input(\"Enter URL :\")\n",
    "cont = int(input(\"enter count:\"))\n",
    "position = int(input(\"enter position:\"))\n",
    "\n",
    "print(\"Retrieving:\", link)\n",
    "for i in range (0, cont):\n",
    "    html=urllib.request.urlopen(link,context=ctx).read()\n",
    "    soup= BeautifulSoup(html, 'html.parser')\n",
    "    tags = soup('a')\n",
    "    cn = 0\n",
    "    ps = 0\n",
    "    for tag in tags:\n",
    "        ps = ps +1\n",
    "        if ps == position :\n",
    "            print(\"Retrieving-----\", str(tag.get('href', None)))\n",
    "            link = str(tag.get('href', None))\n",
    "            ps= 0\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2873\n"
    }
   ],
   "source": [
    "\n",
    "import urllib.request, urllib.parse,urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "ctx= ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url= input(\"Enter - \")\n",
    "html = urlopen(url,context=ctx).read()\n",
    "soup= BeautifulSoup (html, \"html.parser\")\n",
    "\n",
    "tags=soup('span')\n",
    "sum = 0\n",
    "for tag in tags:\n",
    "    sum = sum + int(tag.contents[0])\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2478\n"
    }
   ],
   "source": [
    "import urllib.request, urllib.parse,urllib.error\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "url = input(\"enter your file\")\n",
    "u = urllib.request.urlopen(url)\n",
    "data = u.read()\n",
    "xml_data = ET.fromstring(data)\n",
    "search_str = \"comments/comment\"\n",
    "count_tags = xml_data.findall(search_str)\n",
    "\n",
    "total = 0\n",
    "for tags in count_tags:\n",
    "    c= tags.find('count')\n",
    "    total= total + int(c.text)\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}